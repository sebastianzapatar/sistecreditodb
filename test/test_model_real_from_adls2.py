import unittest
import os
import tempfile
import json
import joblib
import pandas as pd
import numpy as np
from datetime import datetime
from azure.storage.filedatalake import DataLakeServiceClient
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder
from io import StringIO

class RealModelFromADLSTest(unittest.TestCase):
    """Tests reales cargando modelo y datos desde ADLS Gen2 (sin encoders guardados)"""
    
    @classmethod
    def setUpClass(cls):
        """Configurar conexi√≥n a ADLS Gen2 y cargar modelo y datos"""
        print("üî¨ === CARGANDO MODELO REAL DESDE ADLS GEN2 ===")
        
       # Configuraci√≥n ADLS Gen2
        cls.storage_account = "sistecreditofinal"
        cls.storage_key = os.getenv('AZURE_STORAGE_KEY', 'YpYHNOKME38oGXISqD7KFinQ3arvr43JNX59hiWXyTQvj8O7MwMlRQAx/jrPE2bMY+NHAIC0Sub7+AStbzR/Bg==')
        
        # Rutas en ADLS Gen2
        cls.model_container = "raw"
        cls.model_path = "models/random_forest_credit_risk_20250821_112616" 
        cls.data_path = "data/v1/credit_risk_dataset.csv"
        
        try:
            # Crear cliente ADLS Gen2
            cls.service_client = DataLakeServiceClient(
                account_url=f"https://{cls.storage_account}.dfs.core.windows.net",
                credential=cls.storage_key
            )
            cls.file_system_client = cls.service_client.get_file_system_client(cls.model_container)
            
            # Cargar modelo, manifest y datos
            cls.model = cls._load_model()
            cls.manifest = cls._load_manifest()
            cls.full_data = cls._load_full_data()
            
            print("‚úÖ Modelo, manifest y datos cargados exitosamente")
            
        except Exception as e:
            print(f"‚ùå Error configurando ADLS Gen2: {e}")
            cls.model = None
            cls.manifest = None
            cls.full_data = None
    
    @classmethod
    def _download_file(cls, file_path):
        """Descargar archivo desde ADLS Gen2"""
        file_client = cls.file_system_client.get_file_client(file_path)
        download_stream = file_client.download_file()
        return download_stream.readall()
    
    @classmethod
    def _load_model(cls):
        """Cargar modelo desde ADLS Gen2"""
        try:
            model_data = cls._download_file(f"{cls.model_path}/model.joblib")
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.joblib') as tmp_file:
                tmp_file.write(model_data)
                tmp_model_path = tmp_file.name
            
            model = joblib.load(tmp_model_path)
            os.unlink(tmp_model_path)
            
            print(f"‚úÖ Modelo cargado: {type(model).__name__}")
            return model
            
        except Exception as e:
            print(f"‚ùå Error cargando modelo: {e}")
            return None
    
    @classmethod
    def _load_manifest(cls):
        """Cargar manifest desde ADLS Gen2"""
        try:
            manifest_data = cls._download_file(f"{cls.model_path}/manifest.json")
            manifest = json.loads(manifest_data.decode('utf-8'))
            
            print(f"‚úÖ Manifest cargado - Accuracy reportada: {manifest['model_performance']['accuracy']:.3f}")
            return manifest
            
        except Exception as e:
            print(f"‚ùå Error cargando manifest: {e}")
            return None
    
    @classmethod
    def _load_full_data(cls):
        """Cargar dataset completo desde ADLS Gen2"""
        try:
            data_content = cls._download_file(cls.data_path)
            data_string = data_content.decode('utf-8')
            df = pd.read_csv(StringIO(data_string))
            
            print(f"‚úÖ Dataset completo cargado: {len(df)} muestras")
            return df
            
        except Exception as e:
            print(f"‚ùå Error cargando datos: {e}")
            return None
    
    @classmethod
    def _preprocess_credit_data_for_test(cls, df, target_col, train_size=0.8):
        """
        Recrear el MISMO preprocesamiento de tu funci√≥n original
        Dividir en train/test y aplicar encoding basado en train
        """
        
        print("üîÑ === PREPROCESAMIENTO COMO EN ENTRENAMIENTO ===")
        
        # Crear copia para no modificar original
        df_processed = df.copy()
        
        # Limpiar datos (igual que tu funci√≥n)
        print("Limpiando datos...")
        df_processed = df_processed.dropna()
        df_processed = df_processed.drop_duplicates()
        
        print(f"‚úÖ Datos despu√©s de limpieza: {df_processed.shape}")
        
        # Dividir en train/test para recrear encoders
        train_end = int(len(df_processed) * train_size)
        df_train = df_processed.iloc[:train_end].copy()
        df_test = df_processed.iloc[train_end:].copy()
        
        print(f"üìä Split: {len(df_train)} train, {len(df_test)} test")
        
        # Identificar tipos de columnas (igual que tu funci√≥n)
        numeric_cols = df_processed.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()
        
        # Remover target de las listas si est√° presente
        if target_col:
            if target_col in numeric_cols:
                numeric_cols.remove(target_col)
            if target_col in categorical_cols:
                categorical_cols.remove(target_col)
        
        print(f"Columnas num√©ricas ({len(numeric_cols)}): {numeric_cols}")
        print(f"Columnas categ√≥ricas ({len(categorical_cols)}): {categorical_cols}")
        
        # Codificar variables categ√≥ricas BASADO EN TRAIN
        label_encoders = {}
        
        for col in categorical_cols:
            if col != target_col:
                le = LabelEncoder()
                # Entrenar encoder solo con datos de train
                le.fit(df_train[col].astype(str))
                
                # Aplicar a ambos train y test
                df_train[col] = le.transform(df_train[col].astype(str))
                
                # Para test, manejar valores no vistos
                def safe_transform(x):
                    try:
                        return le.transform([str(x)])[0]
                    except ValueError:
                        # Si no se vio en train, usar la primera clase
                        return le.transform([le.classes_])
                
                df_test[col] = df_test[col].astype(str).apply(safe_transform)
                label_encoders[col] = le
        
        # Preparar variable objetivo si es categ√≥rica
        if target_col and target_col in categorical_cols:
            le_target = LabelEncoder()
            le_target.fit(df_train[target_col].astype(str))
            
            df_train[target_col] = le_target.transform(df_train[target_col].astype(str))
            
            def safe_transform_target(x):
                try:
                    return le_target.transform([str(x)])[0]
                except ValueError:
                    return le_target.transform([le_target.classes_])
            
            df_test[target_col] = df_test[target_col].astype(str).apply(safe_transform_target)
            label_encoders[target_col] = le_target
        
        feature_columns = numeric_cols + categorical_cols
        
        print(f"‚úÖ Preprocesamiento completado")
        print(f"üìä Features finales: {len(feature_columns)}")
        
        return df_train, df_test, feature_columns, label_encoders
    
    def setUp(self):
        """Verificar que todo est√© cargado antes de cada test"""
        if self.model is None or self.manifest is None or self.full_data is None:
            self.skipTest("No se pudieron cargar modelo, manifest o datos desde ADLS Gen2")
    
    def test_01_model_loading_validation(self):
        """Test 1: Verificar que modelo y datos se cargaron correctamente"""
        print("\nüß™ Test 1: Validando carga desde ADLS Gen2...")
        
        self.assertIsNotNone(self.model, "Modelo debe estar cargado")
        self.assertIsNotNone(self.manifest, "Manifest debe estar cargado")
        self.assertIsNotNone(self.full_data, "Datos deben estar cargados")
        
        # Verificar que el modelo es RandomForest
        self.assertEqual(self.model.__class__.__name__, 'RandomForestClassifier')
        
        print("‚úÖ Modelo, manifest y datos cargados correctamente desde ADLS Gen2")
  
    
    
    def test_04_data_quality_validation(self):
        """Test 4: Validar calidad de datos"""
        print("\nüß™ Test 4: Validando calidad de datos...")
        
        # Verificar que tenemos datos suficientes
        min_samples = 100
        self.assertGreater(len(self.full_data), min_samples, 
                          f"Dataset {len(self.full_data)} < {min_samples} muestras")
        
        # Verificar que el target existe
        target_column = self.manifest['data_info']['target_column']
        self.assertIn(target_column, self.full_data.columns, f"Target {target_column} no encontrado")
        
        # Verificar distribuci√≥n del target
        target_unique = self.full_data[target_column].nunique()
        self.assertGreater(target_unique, 1, "Target debe tener m√°s de 1 clase √∫nica")
        
        print(f"‚úÖ Datos v√°lidos: {len(self.full_data)} muestras, {target_unique} clases")
    
    def test_05_feature_consistency(self):
        """Test 5: Verificar que las features del manifest existen en los datos"""
        print("\nüß™ Test 5: Validando consistencia de features...")
        
        manifest_features = self.manifest['data_info']['feature_columns']
        data_columns = set(self.full_data.columns)
        
        missing_features = set(manifest_features) - data_columns
        
        if missing_features:
            print(f"‚ö†Ô∏è Features del manifest no encontradas en datos: {missing_features}")
        
        # Al menos 80% de las features deben existir
        existing_features = set(manifest_features) & data_columns
        coverage = len(existing_features) / len(manifest_features)
        
        self.assertGreater(coverage, 0.8, 
                          f"Solo {coverage:.1%} de features del manifest existen en datos")
        
        print(f"‚úÖ Feature coverage: {coverage:.1%} ({len(existing_features)}/{len(manifest_features)})")
    
    def test_06_production_readiness(self):
        """Test 6: Validaci√≥n final de production readiness"""
        print("\nüß™ Test 6: Validando production readiness...")
        
        # Checklist de producci√≥n
        critical_checks = {
            'model_loaded': self.model is not None,
            'manifest_complete': self.manifest is not None,
            'data_available': self.full_data is not None,
            'target_exists': self.manifest['data_info']['target_column'] in self.full_data.columns,
            'features_reasonable': len(self.manifest['data_info']['feature_columns']) >= 3,
            'performance_acceptable': self.manifest['model_performance']['accuracy'] >= 0.50
        }
        
        print("üîç Checklist de producci√≥n:")
        all_passed = True
        for check, status in critical_checks.items():
            print(f"  {'‚úÖ' if status else '‚ùå'} {check}: {status}")
            if not status:
                all_passed = False
        
        if all_passed:
            print("üöÄ Modelo APROBADO para producci√≥n")
        else:
            print("‚ö†Ô∏è Modelo requiere atenci√≥n antes de producci√≥n")
            
        # Solo fallar en problemas cr√≠ticos
        critical_failures = ['model_loaded', 'manifest_complete', 'data_available']
        for critical in critical_failures:
            self.assertTrue(critical_checks[critical], f"Falla cr√≠tica: {critical}")
    
    @classmethod
    def tearDownClass(cls):
        """Cleanup y resumen final"""
        print("\nüéØ === RESUMEN DE VALIDACI√ìN REAL ===")
        print("‚úÖ Modelo cargado desde ADLS Gen2")
        print("‚úÖ Preprocesamiento recreado correctamente")
        print("‚úÖ Performance evaluada con datos reales")
        print("üöÄ VALIDACI√ìN COMPLETADA SIN ENCODERS GUARDADOS")

if __name__ == '__main__':
    # Configurar para output detallado
    unittest.main(verbosity=2, buffer=False)
